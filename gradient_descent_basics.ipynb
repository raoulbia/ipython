{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradient_descent_basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "fpNIRlDq5W92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Gradient Descent Optimization Algorithm\n",
        "\n",
        "<br>\n",
        "\n",
        "On this page I summarize some of the key ideas behind the gradient descent optiization algorithm. The text and code has been lifted and summarized from the blog post\n",
        "[An Introduction to Gradient Descent in Python](https://tillbe.github.io/python-gradient-descent.html). I recommend to visit that page for a more in-depth treatment of the subject matter (and for some great plotting examples). \n",
        "\n",
        "<br>\n",
        "\n",
        "<blockquote>*A Machine Learning model is trained by starting with an initial guess for the weights and bias and iteratively **adjusting those guesses** until learning the weights and bias with the lowest possible loss.*<sup>[1](#quote1)</sup> \n",
        "\n",
        "</blockquote>\n",
        "\n",
        "<a name=\"quote1\">1</a>: [source](https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach.html)\n",
        "\n",
        "<br>\n",
        "\n",
        "* Adjusting guesses is an iterative process:\n",
        "  * iterate until overall loss stops decreasing or decreases extremely slowly.\n",
        "  * at each iteration, adjustments are done by subtracting the true values from the guessed values. The model parameters are then multiplied by the result of the observed difference (referred to as *delta* or *error*).\n",
        "\n",
        "* Initialization of the model parameters\n",
        " * The first stage in gradient descent is to pick starting values for the model parameters. These are stored in a vector $\\Theta$ of size equla to the number of training examples *m*.\n",
        " * Many algorithms initialize $\\Theta$ with zeros or random values.\n",
        " * The gradient descent algorithm then calculates the gradient of the loss curve at the starting values and update $\\Theta$ by multipying its values by the gradients. \n",
        "   \n",
        "   * Note: if theta,is init to  say,  zero values, then in the first iteration the predictions, as well as the values of the corresponding error vector, will all be zeros. Thus, in the first iteration, the vector of observed differences $\\delta$ is equal to -$y$.\n",
        "   \n",
        " * $\\Theta$ is used to decide which feature should have most weight in helping predict the outcome.\n",
        " * $\\Theta$ does not pertain to any specific training example but rather is derived from the training examples size of theta is equal to number of features.\n",
        "\n",
        "<br>\n",
        "\n",
        "**The Gradient Descent process**\n",
        "\n",
        "Below is a barebones description of the *gradient descent* process. It does not include elements such as regularization etc. \n",
        "\n",
        "```  \n",
        "- initialize theta with some values e.g. all zeros\n",
        "- repeat:\n",
        "  - multiply the [m x n] matrix X by the [n x 1] theta vector to obtain a [m x 1] vector of predictions \n",
        "  - subtract the vector of truth values y from the vector of predictions to get a [m x 1] \"delta\" vector of errors i.e. one error for each training example.\n",
        "  - compute gradient:\n",
        "       \n",
        "       gradient = X.T @ delta / m  # [n x 1] = [n x m] x [m x 1]\n",
        "       gradient  = learning rate * gradient\n",
        "  - theta = theta - gradient\n",
        "  - compute cost using theta of current iteration e.g. sum the squared error of delta\n",
        "     \n",
        "```            \n",
        "\n",
        " <br>\n",
        " \n",
        "**Batch vs. Stochastic Gradient Descent** \n",
        "\n",
        "In gradient descent, a batch is the total number of examples used to calculate the gradient in a single iteration. For example the batch can be the entire set of training data. This is a common scenario when implementing gradient descent for say educational *Kaggle* competitions. However in many real life use cases, data sets contain billions or more examples. Using all of the data in one batch may cause even a single iteration to take a very long time to compute.\n",
        "  \n",
        "By choosing examples at random from the data set, it is possible to estimate (albeit, noisily) a big average from a much smaller one. *Stochastic gradient descent (SGD)* takes this idea to the extreme--it uses only a single example (a batch size of 1) per iteration. Given enough iterations, SGD works but is very noisy. The term \"stochastic\" indicates that the one example comprising each batch is chosen at random.\n",
        " \n",
        "      \n",
        "* Some considerations:\n",
        "\n",
        "  * The gradient vector in the batch approach is a vector that is specific to model parameter vector $\\Theta$. If we want a gradient for a specific training example (i.e. * **stochastic** gradient descent*) we could do:\n",
        "       \n",
        "        gradient_i = X[i,:].T @ delta[i]  # [n x 1] = [n x 1] x [1 x 1]\n",
        "       \n",
        "     note how we don't divide by *m* as we only deal with one training example\n",
        "  \n",
        "  * In the batch approach, gradients are summed as part of the matrix multiplication: \n",
        "  \n",
        "        gradient = X.T @ delta / m  # [n x 1] = [n x m] x [m x 1]\n",
        "  \n",
        "     However, when we do * **stochastic** gradient descent* we need to **accumulate** the gradients e.g.:\n",
        "   \n",
        "        Phi[i,:] += gradient_ij\n",
        "        Theta[:, j] += gradient_ij\n",
        "       \n",
        "       \n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "h7vnRS7H5Tq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "779aba0b-9c77-4304-d632-541601a30543"
      },
      "cell_type": "code",
      "source": [
        "# source: https://tillbe.github.io/python-gradient-descent.html\n",
        "\n",
        "# loading necessary libraries and setting up plotting libraries\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets.samples_generator import make_regression \n",
        "from scipy import stats \n",
        "\n",
        "\n",
        "# The make_regression() function will create a dataset with a linear relationship between inputs and the outputs.\n",
        "X, y = make_regression(n_samples = 100, \n",
        "                       n_features=3, \n",
        "                       n_informative=3, \n",
        "                       noise=10,\n",
        "                       random_state=2015)\n",
        "\n",
        "print('X shape', X.shape)\n",
        "print('y shape', y.shape)\n",
        "# print(np.random.rand(X.shape[1], 1))\n",
        "\n",
        "def gradient_descent(X, y, iters, alpha):\n",
        "    costs = []\n",
        "    m = y.size # number of data points\n",
        "    \n",
        "    theta = np.random.rand(X.shape[1]) # [n x 1] \n",
        "    \n",
        "    \n",
        "    \n",
        "    history = [theta] # to store all thetas\n",
        "    preds = []\n",
        "    for i in range(iters):\n",
        "        pred = np.dot(X, theta) # [m x 1] = [m x n] x [n x 1] i.e. a prediction for each example\n",
        "        error = pred - y \n",
        "        \n",
        "        cost = np.sum(error ** 2) / (2 * m)\n",
        "        costs.append(cost)\n",
        "        \n",
        "        if i % 25 == 0: preds.append(pred)\n",
        "\n",
        "        gradient = X.T.dot(error)/m  # [n x 1] = [n x m] x [m x 1]\n",
        "        theta = theta - alpha * gradient  # update\n",
        "        \n",
        "    return theta, costs, preds\n",
        " \n",
        "# add intercet term\n",
        "X = np.c_[np.ones(X.shape[0]), X] \n",
        "\n",
        "alpha = 0.001 # set step-size\n",
        "iters = 5 # set number of iterations\n",
        "theta, cost, preds = gradient_descent(X, y, iters, alpha)\n",
        "\n",
        "print('final theta', theta)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape (100, 3)\n",
            "y shape (100,)\n",
            "final theta [0.96082907 0.64587089 0.78438197 0.19516988]\n",
            "final theta shape (4,)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}